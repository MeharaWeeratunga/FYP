[
  {
    "paperId": "7c25adf2ddb35df05a61c697da97efb8583d77df",
    "title": "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings",
    "venue": "International Symposium on Computer Architecture",
    "year": 2023,
    "citationCount": 358,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3579371.3589350",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://arxiv.org/abs/2304.01433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "publicationDate": "2023-04-04",
    "authors": [
      {
        "authorId": "1715454",
        "name": "N. Jouppi"
      },
      {
        "authorId": "1753079661",
        "name": "George Kurian"
      },
      {
        "authorId": "2153701529",
        "name": "Sheng Li"
      },
      {
        "authorId": "49735130",
        "name": "Peter C. Ma"
      },
      {
        "authorId": "1395811464",
        "name": "R. Nagarajan"
      },
      {
        "authorId": "2144577",
        "name": "Lifeng Nai"
      },
      {
        "authorId": "2056800684",
        "name": "Nishant Patil"
      },
      {
        "authorId": "1929462",
        "name": "Suvinay Subramanian"
      },
      {
        "authorId": "1394189636",
        "name": "Andy Swing"
      },
      {
        "authorId": "1762455",
        "name": "Brian Towles"
      },
      {
        "authorId": "39660914",
        "name": "C. Young"
      },
      {
        "authorId": "50177639",
        "name": "Xiaoping Zhou"
      },
      {
        "authorId": "2109465503",
        "name": "Zongwei Zhou"
      },
      {
        "authorId": "2052996328",
        "name": "David A. Patterson"
      }
    ],
    "abstract": "In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are <5% of system cost and <3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x--7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus nearly 10x faster overall, which along with OCS flexibility and availability allows a large language model to train at an average of ~60% of peak FLOPS/second. For similar sized systems, it is ~4.3x--4.5x faster than the Graphcore IPU Bow and is 1.2x--1.7x faster and uses 1.3x--1.9x less power than the Nvidia A100. TPU v4s inside the energy-optimized warehouse scale computers of Google Cloud use ~2--6x less energy and produce ~20x less CO2e than contemporary DSAs in typical on-premise data centers.",
    "is_cs_paper": true,
    "search_query": "machine learning",
    "collection_date": "2025-06-19T00:36:15.896089"
  },
  {
    "paperId": "df70977e0347b76fb049c17c3956f643bcb43a55",
    "title": "Understanding of Machine Learning with Deep Learning: Architectures, Workflow, Applications and Future Directions",
    "venue": "De Computis",
    "year": 2023,
    "citationCount": 530,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2073-431X/12/5/91/pdf?version=1682405138",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/computers12050091?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/computers12050091, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "publicationDate": "2023-04-25",
    "authors": [
      {
        "authorId": "2013359",
        "name": "Mohammad Mustafa Taye"
      }
    ],
    "abstract": "In recent years, deep learning (DL) has been the most popular computational approach in the field of machine learning (ML), achieving exceptional results on a variety of complex cognitive tasks, matching or even surpassing human performance. Deep learning technology, which grew out of artificial neural networks (ANN), has become a big deal in computing because it can learn from data. The ability to learn enormous volumes of data is one of the benefits of deep learning. In the past few years, the field of deep learning has grown quickly, and it has been used successfully in a wide range of traditional fields. In numerous disciplines, including cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, deep learning has outperformed well-known machine learning approaches. In order to provide a more ideal starting point from which to create a comprehensive understanding of deep learning, also, this article aims to provide a more detailed overview of the most significant facets of deep learning, including the most current developments in the field. Moreover, this paper discusses the significance of deep learning and the various deep learning techniques and networks. Additionally, it provides an overview of real-world application areas where deep learning techniques can be utilised. We conclude by identifying possible characteristics for future generations of deep learning modelling and providing research suggestions. On the same hand, this article intends to provide a comprehensive overview of deep learning modelling that can serve as a resource for academics and industry people alike. Lastly, we provide additional issues and recommended solutions to assist researchers in comprehending the existing research gaps. Various approaches, deep learning architectures, strategies, and applications are discussed in this work.",
    "is_cs_paper": true,
    "search_query": "machine learning",
    "collection_date": "2025-06-19T00:36:15.896125"
  },
  {
    "paperId": "38f0b605b289e965f03c326086e4139a2c3cc3a4",
    "title": "MRI-based brain tumor detection using convolutional deep learning methods and chosen machine learning techniques",
    "venue": "BMC Medical Informatics and Decision Making",
    "year": 2023,
    "citationCount": 292,
    "openAccessPdf": {
      "url": "https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-023-02114-6",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC9872362, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Medicine",
      "Computer Science"
    ],
    "publicationDate": "2023-01-23",
    "authors": [
      {
        "authorId": "51221812",
        "name": "Soheila Saeedi"
      },
      {
        "authorId": "73182257",
        "name": "S. Rezayi"
      },
      {
        "authorId": "29992148",
        "name": "Hamidreza Keshavarz"
      },
      {
        "authorId": "114597549",
        "name": "Sharareh R. Niakan Kalhori"
      }
    ],
    "abstract": "Background Detecting brain tumors in their early stages is crucial. Brain tumors are classified by biopsy, which can only be performed through definitive brain surgery. Computational intelligence-oriented techniques can help physicians identify and classify brain tumors. Herein, we proposed two deep learning methods and several machine learning approaches for diagnosing three types of tumor, i.e., glioma, meningioma, and pituitary gland tumors, as well as healthy brains without tumors, using magnetic resonance brain images to enable physicians to detect with high accuracy tumors in early stages. Materials and Methods A dataset containing 3264 Magnetic Resonance Imaging (MRI) brain images comprising images of glioma, meningioma, pituitary gland tumors, and healthy brains were used in this study. First, preprocessing and augmentation algorithms were applied to MRI brain images. Next, we developed a new 2D Convolutional Neural Network (CNN) and a convolutional auto-encoder network, both of which were already trained by our assigned hyperparameters. Then 2D CNN includes several convolution layers; all layers in this hierarchical network have a 2*2 kernel function. This network consists of eight convolutional and four pooling layers, and after all convolution layers, batch-normalization layers were applied. The modified auto-encoder network includes a convolutional auto-encoder network and a convolutional network for classification that uses the last output encoder layer of the first part. Furthermore, six machine-learning techniques that were applied to classify brain tumors were also compared in this study. Results The training accuracy of the proposed 2D CNN and that of the proposed auto-encoder network were found to be 96.47% and 95.63%, respectively. The average recall values for the 2D CNN and auto-encoder networks were 95% and 94%, respectively. The areas under the ROC curve for both networks were 0.99 or 1. Among applied machine learning methods, Multilayer Perceptron (MLP) (28%) and K-Nearest Neighbors (KNN) (86%) achieved the lowest and highest accuracy rates, respectively. Statistical tests showed a significant difference between the means of the two methods developed in this study and several machine learning methods ( p -value < 0.05). Conclusion The present study shows that the proposed 2D CNN has optimal accuracy in classifying brain tumors. Comparing the performance of various CNNs and machine learning methods in diagnosing three types of brain tumors revealed that the 2D CNN achieved exemplary performance and optimal execution time without latency. This proposed network is less complex than the auto-encoder network and can be employed by radiologists and physicians in clinical systems for brain tumor detection.",
    "is_cs_paper": true,
    "search_query": "machine learning",
    "collection_date": "2025-06-19T00:36:15.896135"
  },
  {
    "paperId": "e795f62df9ccac2a39e126f95404e5364d55193c",
    "title": "FuXi: a cascade machine learning forecasting system for 15-day global weather forecast",
    "venue": "npj Climate and Atmospheric Science",
    "year": 2023,
    "citationCount": 221,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2306.12873",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://arxiv.org/abs/2306.12873, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Computer Science",
      "Physics"
    ],
    "publicationDate": "2023-06-22",
    "authors": [
      {
        "authorId": "2047937397",
        "name": "Lei Chen"
      },
      {
        "authorId": "49834936",
        "name": "Xiaohui Zhong"
      },
      {
        "authorId": "7855699",
        "name": "Feng-jun Zhang"
      },
      {
        "authorId": "145591949",
        "name": "Yuan Cheng"
      },
      {
        "authorId": "2266466742",
        "name": "Yinghui Xu"
      },
      {
        "authorId": "2192603365",
        "name": "Yuan Qi"
      },
      {
        "authorId": "2195889904",
        "name": "Hao Li"
      }
    ],
    "abstract": "Over the past few years, the rapid development of machine learning (ML) models for weather forecasting has led to state-of-the-art ML models that have superior performance compared to the European Centre for Medium-Range Weather Forecasts (ECMWF)’s high-resolution forecast (HRES), which is widely considered as the world’s best physics-based weather forecasting system. Specifically, ML models have outperformed HRES in 10-day forecasts with a spatial resolution of 0.25^∘. However, the challenge remains in mitigating the accumulation of forecast errors for longer effective forecasts, such as achieving comparable performance to the ECMWF ensemble in 15-day forecasts. Despite various efforts to reduce accumulation errors, such as implementing autoregressive multi-time step loss, relying on a single model has been found to be insufficient for achieving optimal performance in both short and long lead times. Therefore, we present FuXi, a cascaded ML weather forecasting system that provides 15-day global forecasts at a temporal resolution of 6 hours and a spatial resolution of 0.25^∘. FuXi is developed using 39 years of the ECMWF ERA5 reanalysis dataset. The performance evaluation demonstrates that FuXi has forecast performance comparable to ECMWF ensemble mean (EM) in 15-day forecasts. FuXi surpasses the skillful forecast lead time achieved by ECMWF HRES by extending the lead time for Z500 from 9.25 to 10.5 days and for T2M from 10 to 14.5 days. Moreover, the FuXi ensemble is created by perturbing initial conditions and model parameters, enabling it to provide forecast uncertainty and demonstrating promising results when compared to the ECMWF ensemble.",
    "is_cs_paper": true,
    "search_query": "machine learning",
    "collection_date": "2025-06-19T00:36:15.896144"
  },
  {
    "paperId": "4e08141db0f2aa01afe903d312011c7d3d7acc46",
    "title": "Scaling deep learning for materials discovery",
    "venue": "Nature",
    "year": 2023,
    "citationCount": 665,
    "openAccessPdf": {
      "url": "https://www.nature.com/articles/s41586-023-06735-9.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10700131, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Computer Science",
      "Medicine"
    ],
    "publicationDate": "2023-11-29",
    "authors": [
      {
        "authorId": "1411034322",
        "name": "Amil Merchant"
      },
      {
        "authorId": "2268751984",
        "name": "Simon Batzner"
      },
      {
        "authorId": "2601641",
        "name": "S. Schoenholz"
      },
      {
        "authorId": "7995028",
        "name": "Muratahan Aykol"
      },
      {
        "authorId": "2268315391",
        "name": "Gowoon Cheon"
      },
      {
        "authorId": "8132903",
        "name": "E. D. Cubuk"
      }
    ],
    "abstract": "Novel functional materials enable fundamental breakthroughs across technological applications from clean energy to information processing^ 1 – 11 . From microchips to batteries and photovoltaics, discovery of inorganic crystals has been bottlenecked by expensive trial-and-error approaches. Concurrently, deep-learning models for language, vision and biology have showcased emergent predictive capabilities with increasing data and computation^ 12 – 14 . Here we show that graph networks trained at scale can reach unprecedented levels of generalization, improving the efficiency of materials discovery by an order of magnitude. Building on 48,000 stable crystals identified in continuing studies^ 15 – 17 , improved efficiency enables the discovery of 2.2 million structures below the current convex hull, many of which escaped previous human chemical intuition. Our work represents an order-of-magnitude expansion in stable materials known to humanity. Stable discoveries that are on the final convex hull will be made available to screen for technological applications, as we demonstrate for layered materials and solid-electrolyte candidates. Of the stable structures, 736 have already been independently experimentally realized. The scale and diversity of hundreds of millions of first-principles calculations also unlock modelling capabilities for downstream applications, leading in particular to highly accurate and robust learned interatomic potentials that can be used in condensed-phase molecular-dynamics simulations and high-fidelity zero-shot prediction of ionic conductivity. A protocol using large-scale training of graph networks enables high-throughput discovery of novel stable structures and led to the identification of 2.2 million crystal structures, of which 381,000 are newly discovered stable materials.",
    "is_cs_paper": true,
    "search_query": "deep learning",
    "collection_date": "2025-06-19T00:36:19.860581"
  },
  {
    "paperId": "df70977e0347b76fb049c17c3956f643bcb43a55",
    "title": "Understanding of Machine Learning with Deep Learning: Architectures, Workflow, Applications and Future Directions",
    "venue": "De Computis",
    "year": 2023,
    "citationCount": 530,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2073-431X/12/5/91/pdf?version=1682405138",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://api.unpaywall.org/v2/10.3390/computers12050091?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/computers12050091, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "publicationDate": "2023-04-25",
    "authors": [
      {
        "authorId": "2013359",
        "name": "Mohammad Mustafa Taye"
      }
    ],
    "abstract": "In recent years, deep learning (DL) has been the most popular computational approach in the field of machine learning (ML), achieving exceptional results on a variety of complex cognitive tasks, matching or even surpassing human performance. Deep learning technology, which grew out of artificial neural networks (ANN), has become a big deal in computing because it can learn from data. The ability to learn enormous volumes of data is one of the benefits of deep learning. In the past few years, the field of deep learning has grown quickly, and it has been used successfully in a wide range of traditional fields. In numerous disciplines, including cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, deep learning has outperformed well-known machine learning approaches. In order to provide a more ideal starting point from which to create a comprehensive understanding of deep learning, also, this article aims to provide a more detailed overview of the most significant facets of deep learning, including the most current developments in the field. Moreover, this paper discusses the significance of deep learning and the various deep learning techniques and networks. Additionally, it provides an overview of real-world application areas where deep learning techniques can be utilised. We conclude by identifying possible characteristics for future generations of deep learning modelling and providing research suggestions. On the same hand, this article intends to provide a comprehensive overview of deep learning modelling that can serve as a resource for academics and industry people alike. Lastly, we provide additional issues and recommended solutions to assist researchers in comprehending the existing research gaps. Various approaches, deep learning architectures, strategies, and applications are discussed in this work.",
    "is_cs_paper": true,
    "search_query": "deep learning",
    "collection_date": "2025-06-19T00:36:19.860608"
  },
  {
    "paperId": "4a07ded5f56aa76c75e844f353e046414b427cc2",
    "title": "A survey on deep learning tools dealing with data scarcity: definitions, challenges, solutions, tips, and applications",
    "venue": "Journal of Big Data",
    "year": 2023,
    "citationCount": 433,
    "openAccessPdf": {
      "url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-023-00727-2",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1186/s40537-023-00727-2?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1186/s40537-023-00727-2, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "publicationDate": "2023-04-14",
    "authors": [
      {
        "authorId": "2281247548",
        "name": "Laith Alzubaidi"
      },
      {
        "authorId": "2048597283",
        "name": "Jinshuai Bai"
      },
      {
        "authorId": "1411258793",
        "name": "Aiman Al-Sabaawi"
      },
      {
        "authorId": "2146732191",
        "name": "José I. Santamaría"
      },
      {
        "authorId": "145400504",
        "name": "A. Albahri"
      },
      {
        "authorId": "1580197731",
        "name": "B. S. Al-dabbagh"
      },
      {
        "authorId": "1412407676",
        "name": "M. Fadhel"
      },
      {
        "authorId": "2448516",
        "name": "M. Manoufali"
      },
      {
        "authorId": "2214539205",
        "name": "Jinglan Zhang"
      },
      {
        "authorId": "1404550727",
        "name": "Ali H. Al-timemy"
      },
      {
        "authorId": "2151245099",
        "name": "Ye Duan"
      },
      {
        "authorId": "2214474453",
        "name": "Amjed Abdullah"
      },
      {
        "authorId": "144121680",
        "name": "Laith Farhan"
      },
      {
        "authorId": "2143774159",
        "name": "Yi Lu"
      },
      {
        "authorId": "2204829304",
        "name": "Ashish Gupta"
      },
      {
        "authorId": "2214471161",
        "name": "Felix Albu"
      },
      {
        "authorId": "2214474151",
        "name": "Amin Abbosh"
      },
      {
        "authorId": "2153395256",
        "name": "Yuantong Gu"
      }
    ],
    "abstract": "Data scarcity is a major challenge when training deep learning (DL) models. DL demands a large amount of data to achieve exceptional performance. Unfortunately, many applications have small or inadequate data to train DL frameworks. Usually, manual labeling is needed to provide labeled data, which typically involves human annotators with a vast background of knowledge. This annotation process is costly, time-consuming, and error-prone. Usually, every DL framework is fed by a significant amount of labeled data to automatically learn representations. Ultimately, a larger amount of data would generate a better DL model and its performance is also application dependent. This issue is the main barrier for many applications dismissing the use of DL. Having sufficient data is the first step toward any successful and trustworthy DL application. This paper presents a holistic survey on state-of-the-art techniques to deal with training DL models to overcome three challenges including small, imbalanced datasets, and lack of generalization. This survey starts by listing the learning techniques. Next, the types of DL architectures are introduced. After that, state-of-the-art solutions to address the issue of lack of training data are listed, such as Transfer Learning (TL), Self-Supervised Learning (SSL), Generative Adversarial Networks (GANs), Model Architecture (MA), Physics-Informed Neural Network (PINN), and Deep Synthetic Minority Oversampling Technique (DeepSMOTE). Then, these solutions were followed by some related tips about data acquisition needed prior to training purposes, as well as recommendations for ensuring the trustworthiness of the training dataset. The survey ends with a list of applications that suffer from data scarcity, several alternatives are proposed in order to generate more data in each application including Electromagnetic Imaging (EMI), Civil Structural Health Monitoring, Medical imaging, Meteorology, Wireless Communications, Fluid Mechanics, Microelectromechanical system, and Cybersecurity. To the best of the authors’ knowledge, this is the first review that offers a comprehensive overview on strategies to tackle data scarcity in DL.",
    "is_cs_paper": true,
    "search_query": "deep learning",
    "collection_date": "2025-06-19T00:36:19.860615"
  },
  {
    "paperId": "3f3b35fa0b8b942bcae7c755603ce56de616da93",
    "title": "Deep learning modelling techniques: current progress, applications, advantages, and challenges",
    "venue": "Artificial Intelligence Review",
    "year": 2023,
    "citationCount": 370,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10462-023-10466-8.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: This content is from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10462-023-10466-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10462-023-10466-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "fieldsOfStudy": [
      "Computer Science"
    ],
    "publicationDate": "2023-04-17",
    "authors": [
      {
        "authorId": "2191712324",
        "name": "S. Ahmed"
      },
      {
        "authorId": "2109951702",
        "name": "Md. Sakib Bin Alam"
      },
      {
        "authorId": "2148761474",
        "name": "Maruf Hassan"
      },
      {
        "authorId": "2123503716",
        "name": "M. R. Rozbu"
      },
      {
        "authorId": "29882602",
        "name": "Taoseef Ishtiak"
      },
      {
        "authorId": "121492699",
        "name": "Nazifa Rafa"
      },
      {
        "authorId": "30576247",
        "name": "M. Mofijur"
      },
      {
        "authorId": "2267256956",
        "name": "A. B. M. Shawkat Ali"
      },
      {
        "authorId": "2238700690",
        "name": "Amir H. Gandomi"
      }
    ],
    "abstract": "Deep learning (DL) is revolutionizing evidence-based decision-making techniques that can be applied across various sectors. Specifically, it possesses the ability to utilize two or more levels of non-linear feature transformation of the given data via representation learning in order to overcome limitations posed by large datasets. As a multidisciplinary field that is still in its nascent phase, articles that survey DL architectures encompassing the full scope of the field are rather limited. Thus, this paper comprehensively reviews the state-of-art DL modelling techniques and provides insights into their advantages and challenges. It was found that many of the models exhibit a highly domain-specific efficiency and could be trained by two or more methods. However, training DL models can be very time-consuming, expensive, and requires huge samples for better accuracy. Since DL is also susceptible to deception and misclassification and tends to get stuck on local minima, improved optimization of parameters is required to create more robust models. Regardless, DL has already been leading to groundbreaking results in the healthcare, education, security, commercial, industrial, as well as government sectors. Some models, like the convolutional neural network (CNN), generative adversarial networks (GAN), recurrent neural network (RNN), recursive neural networks, and autoencoders, are frequently used, while the potential of other models remains widely unexplored. Pertinently, hybrid conventional DL architectures have the capacity to overcome the challenges experienced by conventional models. Considering that capsule architectures may dominate future DL models, this work aimed to compile information for stakeholders involved in the development and use of DL models in the contemporary world.",
    "is_cs_paper": true,
    "search_query": "deep learning",
    "collection_date": "2025-06-19T00:36:19.860618"
  }
]